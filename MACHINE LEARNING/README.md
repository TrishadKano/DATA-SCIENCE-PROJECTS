## Welcome to My Repository! ðŸš€

- This repository is a showcase of my technical expertise and hands-on experience in Data Science, Data Analysis, and SQL. Each project here reflects my ability to solve real-world challenges, explore emerging technologies, and deliver practical, data-driven solutions.

 - The projects focus on hands-on experience in data preprocessing, model development, and performance evaluation. Each project is designed to help me gain practical skills in key areas of Data Science ðŸ¤–.

## Project List


## Project: Credit Risk Assessment using Logistic Regression, Random Forest, and Decision Tree Classifier

## Overview:
- This project predicts the credit risk of applicants by classifying them into Default or Not Default categories. Using Python and machine learning algorithms, the model helps financial institutions evaluate creditworthiness, reduce default risk, and make data-driven lending decisions.

## Aim:
- To build an accurate classification model that distinguishes between applicants who are likely to default and those who are not, improving decision-making in credit risk assessment.

### Key Features:

- Data exploration, cleaning, and preprocessing

- Implementation of multiple classification models (Logistic Regression, Random Forest, Decision Tree)

- Model evaluation and comparison using Accuracy, Precision, Recall, F1-score, and ROC-AUC

- Data visualization of trends and risk indicators related to defaults

- Use of Python libraries such as Pandas, NumPy, Scikit-learn, and Matplotlib

### Technologies Used:

- Python

- Machine Learning (Classification Algorithms)

- Data Visualization


## Project: Credit Scoring using Decision Tree Classifier

### Overview:
- This project focuses on building a credit scoring model to evaluate the creditworthiness of applicants. Unlike credit risk assessment (which classifies applications as Default vs Not Default), credit scoring assigns a score that reflects the applicantâ€™s likelihood of repayment. Using a Decision Tree Classifier, the model provides a transparent and interpretable approach to credit scoring, aiding financial institutions in making data-driven lending decisions.

### Aim:
- To develop a Decision Treeâ€“based credit scoring model that predicts an applicantâ€™s creditworthiness, helping lenders assess risk levels more effectively and improve loan approval processes.

### Key Features:

- Data exploration, cleaning, and preprocessing for scoring features

- Implementation of a Decision Tree Classifier for credit scoring

- Model evaluation using Accuracy, Precision, Recall, F1-score, and ROC-AUC

- Visualization of decision rules and feature importance for interpretability

- Use of Python libraries such as Pandas, NumPy, Scikit-learn, and Matplotlib

### Technologies Used:

- Python

- Machine Learning (Decision Tree Classifier)

- Data Visualization




## Project : LLM Chatbot Using Google Gemini Pro ðŸ¤–âœ¨

## Description:
- In this project, I developed a chatbot system integrated with Google's Gemini Pro LLM (Large Language Model) API. The chatbot leverages Gemini Pro's advanced natural language understanding and generation capabilities to engage in intelligent, human-like conversations. It is deployed using Streamlit, enabling an interactive and responsive web-based user interface for seamless real-time communication.

### Aim:

- To build and deploy an LLM-based chatbot using Google Gemini Pro that provides dynamic, context-aware conversational responses to user inputs for tasks such as general Q&A, summarisation, and assistance, enhancing productivity and user experience.

### Tools Used:

- Python (Requests, Streamlit)

- Google Gemini Pro API

- Streamlit (for user interface and deployment)

## Project : Exploratory Data Analysis (EDA) on a Public DatasetðŸ“Š

### Description:

- Performed Exploratory Data Analysis (EDA) on a publicly available dataset Titanic dataset from Kaggle).

- Cleaned the data, handled missing values, and conducted basic statistical analysis.

- Visualised data distributions, correlations, and key patterns using charts and graphs.

### Aim:


- To explore, clean, and visualise the Titanic dataset to uncover patterns, correlations, and insights that inform survival outcomes.

### Tools Used:

- Python (Pandas, Matplotlib, Seaborn)

- Jupyter Notebook


## Project: Amazon Tesla Review Sentiment Analysis ðŸš—ðŸ“Š

### Description:
- In this project, I developed a sentiment analysis system to classify Amazon customer reviews for Tesla products into positive and negative sentiments. The project involves data scraping, preprocessing, and building a machine learning model to identify customer perceptions and feedback trends. This enables businesses and analysts to gain insights into customer satisfaction and areas requiring improvement.

### Aim:

- To build and deploy a sentiment analysis model that accurately classifies Amazon Tesla product reviews, thereby assisting in understanding customer opinions, enhancing product development strategies, and supporting data-driven business decisions.

### Tools Used:
- Python (pandas, numpy, scikit-learn, requests)

- scikit-learn (for model building, training, and evaluation)

- pandas & numpy (for data manipulation and preprocessing)

- Jupyter Notebook (for development and experimentation)
  
- Streamlit (for user interface and deployment)



## Project : Simple Linear Regression on Housing Prices (Model Building)

### Description:

- Used a housing prices dataset (Boston Housing dataset).

- Performed data preprocessing, including feature selection and normalisation.

- Built a linear regression model to predict house prices based on features like the number of rooms, square footage, etc.

### Aim:


- To build a predictive model using simple linear regression for estimating housing prices based on key numerical features in the Boston Housing dataset.

### Tools Used:

- Python (Pandas, Scikit-learn, Matplotlib, Seaborn)

- Jupyter Notebook



## Project : Loan Eligibility Prediction using Logistic Regression, RandomForest anf DecisionTree classifier

### Overview:

- This project aims to predict loan eligibility based on applicant data. Using Python and machine learning algorithms, the model classifies whether a loan application is Approved or Not Approved.

### Aim:


- To develop a classification model that accurately predicts loan eligibility based on applicant information, improving decision-making in loan approval processes.

### Key Features:

- Data exploration and preprocessing

- Implementation of machine learning models

- Evaluation of model performance

- Use of Python libraries such as Pandas, NumPy, Scikit-learn, and Matplotlib

### Technologies Used:

- Python

- Machine Learning (Classification Algorithms)

- Data Visualisation



## Project : Credit_Fraud_Detection using Logistic Regression


### Description:


- In this project, I built a credit card fraud detection system using Logistic Regression to classify transactions as fraudulent or legitimate based on transaction data patterns. The objective was to detect anomalies in financial transactions and reduce false positives through proper model evaluation and preprocessing steps.

### Aim:


- To develop a machine learning model using Logistic Regression that accurately classifies credit card transactions as either fraudulent or legitimate, enhancing fraud detection capability and minimizing financial losses.

### Tools Used:


- Python (Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn)

- Jupyter Notebook



## Project : Disease Prediction System Using SVM ðŸ©º


### Description


- In this project, I developed a machine learning-based system to predict whether a patient is diabetic or not, using the Support Vector Machine (SVM) algorithm. SVM was chosen for its effectiveness in handling high-dimensional data and binary classification problems. The system analyzes healthcare datasets containing features such as blood pressure, glucose levels, BMI, age, and other relevant patient information to provide accurate predictions.


### Aim:


- To build and deploy a real-time diabetes prediction system that determines whether a patient is diabetic or not, supporting early diagnosis and timely medical intervention.

### Tools Used:


- Python (Pandas, NumPy, Scikit-learn, Streamlit)

- Jupyter Notebook for development and experimentation

- Streamlit (for model deployment and user interface)




## Project : Customer Segmentation Using K-Means and PCA



### Description


- In this project, I performed customer segmentation using K-Means clustering and Principal Component Analysis (PCA) to identify distinct customer groups based on purchasing behavior. The goal was to enable data-driven marketing strategies by understanding customer profiles and preferences.


### Aim:


- To apply unsupervised learning techniques for segmenting customers into meaningful groups based on behavioral data, supporting personalized marketing and customer retention strategies.

### Tools Used:

- Python (Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn)

- Jupyter Notebook



